{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMITmsOaK3TjLZWNHOhf31g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shijuc/CGAN_Demo/blob/master/CGAN_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WB1CXo4jza96"
      },
      "outputs": [],
      "source": [
        "from __future__ import division, print_function\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "import itertools\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Activation, Dense, Flatten, GlobalAveragePooling2D, BatchNormalization, Dropout, Conv2D, Conv2DTranspose, AveragePooling2D, MaxPooling2D, UpSampling2D, Input, Reshape, Lambda, Concatenate, Subtract, Reshape, multiply\n",
        "from keras.layers import Embedding, ZeroPadding2D\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import LeakyReLU\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Nadam, Adam, SGD\n",
        "from keras.metrics import categorical_accuracy, binary_accuracy\n",
        "from keras.callbacks import Callback, History\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import glob\n",
        "import PIL\n",
        "from sys import getsizeof\n",
        "from PIL import Image\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "from sklearn.utils import class_weight\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# Image shape information\n",
        "img_rows = X_train.shape[1]\n",
        "img_cols = X_train.shape[2]\n",
        "\n",
        "if len(X_train.shape) == 4:\n",
        "    channels = X_train.shape[3]\n",
        "else:\n",
        "    channels = 1\n",
        "img_shape = (img_rows, img_cols, channels)\n",
        "num_classes = 10\n",
        "latent_dim = 100\n",
        "optimizer = Adam(0.0002, 0.5)"
      ],
      "metadata": {
        "id": "rqlOXWUxzptd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, input_dim=np.prod(img_shape)))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.summary()\n",
        "\n",
        "    img = Input(shape=img_shape)\n",
        "    label = Input(shape=(1,), dtype='int32')\n",
        "\n",
        "    label_embedding = Flatten()(Embedding(num_classes, np.prod(img_shape))(label))\n",
        "    flat_img = Flatten()(img)\n",
        "\n",
        "    model_input = multiply([flat_img, label_embedding])\n",
        "\n",
        "    validity = model(model_input)\n",
        "\n",
        "    return Model([img, label], validity)"
      ],
      "metadata": {
        "id": "OuDFoVa52j7L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256, input_dim=latent_dim))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(1024))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(np.prod(img_shape), activation='tanh'))\n",
        "    model.add(Reshape(img_shape))\n",
        "    model.summary()\n",
        "\n",
        "    noise = Input(shape=(latent_dim,))\n",
        "    label = Input(shape=(1,), dtype='int32')\n",
        "    label_embedding = Flatten()(Embedding(num_classes, latent_dim)(label))\n",
        "\n",
        "    model_input = multiply([noise, label_embedding])\n",
        "    img = model(model_input)\n",
        "\n",
        "    return Model([noise, label], img)"
      ],
      "metadata": {
        "id": "gn3wSnPg0mN1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = discriminator()\n",
        "\n",
        "discriminator.compile(loss=['binary_crossentropy'], optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Build the generator\n",
        "generator = generator()\n",
        "\n",
        "# The generator takes noise and the target label as input\n",
        "# and generates the corresponding digit of that label\n",
        "\n",
        "noise = Input(shape=(latent_dim,))\n",
        "label = Input(shape=(1,))\n",
        "img = generator([noise, label])\n",
        "\n",
        "# For the combined model we will only train the generator\n",
        "discriminator.trainable = False\n",
        "\n",
        "# The discriminator takes generated image as input and determines validity\n",
        "# and the label of that image\n",
        "valid = discriminator([img, label])\n",
        "\n",
        "# The combined model  (stacked generator and discriminator)\n",
        "# Trains generator to fool discriminator\n",
        "\n",
        "combined = Model([noise, label], valid)\n",
        "combined.compile(loss=['binary_crossentropy'], optimizer=optimizer)"
      ],
      "metadata": {
        "id": "mlnlm3PYxhI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_images(epoch):\n",
        "    r, c = 2, 5\n",
        "    noise = np.random.normal(0, 1, (r * c, 100))\n",
        "    sampled_labels = np.arange(0, 10).reshape(-1, 1)\n",
        "    for i in range(0, len(sampled_labels)):\n",
        "        print(sampled_labels[i])\n",
        "    gen_imgs = generator.predict([noise, sampled_labels])\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    cnt = 0\n",
        "    for i in range(2 * 5):\n",
        "      plt.axis('off')\n",
        "      plt.imshow(gen_imgs[cnt,:,:,0], cmap='gray')\n",
        "      cnt += 1\n",
        "      filename = \"/content/%d\" % sampled_labels[cnt-1]\n",
        "\n",
        "      if not os.path.exists(filename):\n",
        "          os.makedirs(filename)\n",
        "      plt.savefig(\"/content/%d/%d.png\" % ( sampled_labels[cnt-1], epoch))\n",
        "\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "w0MELPswyCAm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=5000\n",
        "batch_size=32\n",
        "sample_interval=500"
      ],
      "metadata": {
        "id": "IpfgIRXJyIxN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "y_train = y_train.reshape(-1, 1)\n",
        "\n",
        "# Adversarial ground truths\n",
        "valid = np.ones((batch_size, 1))\n",
        "fake = np.zeros((batch_size, 1))\n",
        "\n",
        "# Declaring empty lists to save the losses for plotting\n",
        "d_loss_plot = []\n",
        "g_loss_plot = []\n",
        "acc_plot = []"
      ],
      "metadata": {
        "id": "GND5JtjVyLXt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    #Training the Discriminator\n",
        "    # Select a random half batch of images\n",
        "    idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "    imgs, labels = X_train[idx], y_train[idx]\n",
        "\n",
        "    # Sample noise as generator input\n",
        "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
        "\n",
        "    # Generate a half batch of new images\n",
        "    gen_imgs = generator.predict([noise, labels])\n",
        "\n",
        "    # Train the discriminator\n",
        "    d_loss_real = discriminator.train_on_batch([imgs, labels], valid)\n",
        "    d_loss_fake = discriminator.train_on_batch([gen_imgs, labels], fake)\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "    #Training the Generator\n",
        "    # Condition on labels\n",
        "    sampled_labels = np.random.randint(0, 10, batch_size).reshape(-1, 1)\n",
        "\n",
        "    # Train the generator\n",
        "    g_loss = combined.train_on_batch([noise, sampled_labels], valid)\n",
        "\n",
        "    # Saving the Discriminator and Generator losses and accuracy for plotting\n",
        "    d_loss_plot.append(d_loss[0])\n",
        "    g_loss_plot.append(g_loss)\n",
        "    acc_plot.append(d_loss[1])\n",
        "\n",
        "    # Plot the progress every 500 epochs\n",
        "    if epoch % 500 == 0:\n",
        "        print (\"%d/%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, epochs, d_loss[0], 100*d_loss[1], g_loss))\n",
        "        samples = 10\n",
        "        z = np.random.normal(loc=0, scale=1, size=(samples, latent_dim))\n",
        "        labels = np.arange(0, 10).reshape(-1, 1)\n",
        "        x_fake = generator.predict([z, labels])\n",
        "        cnt=0\n",
        "        for k in range(samples):\n",
        "            plt.subplot(2, 5, k+1)\n",
        "            plt.imshow(x_fake[k].reshape(28, 28), cmap='gray')\n",
        "            #plt.axes.axes.set_title(\"Digit: %d\" % sampled_labels[cnt])\n",
        "            plt.xticks([])\n",
        "            plt.yticks([])\n",
        "            cnt+=1\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # Saving generated image samples at every sample interval\n",
        "    if epoch % sample_interval == 0:\n",
        "        sample_images(epoch)"
      ],
      "metadata": {
        "id": "T2FQpBw0ySXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(acc_plot)\n",
        "\n",
        "plt.title('Discriminator accuracy')\n",
        "\n",
        "plt.ylabel('accuracy')\n",
        "\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Loss plots\n",
        "\n",
        "plt.plot(d_loss_plot)\n",
        "\n",
        "plt.plot(g_loss_plot)\n",
        "\n",
        "plt.title('Losses')\n",
        "\n",
        "plt.ylabel('loss')\n",
        "\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "plt.legend(['Discriminator', 'Generator'])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UQRcO9Ek0_Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/content.zip /content/*"
      ],
      "metadata": {
        "id": "nxAzP6_N1MtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import unique,argmax\n",
        "from keras.datasets.mnist import load_data\n",
        "from keras.layers import Conv2D,MaxPool2D,Dense,Flatten,Dropout\n",
        "from keras.utils import plot_model\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "4ZjNdEEP1YrM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the contents of Zip File\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/content.zip', 'r') as zip:\n",
        "    zip.extractall('/content')"
      ],
      "metadata": {
        "id": "lI4IXqmb3B1I"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the Mnist dataset\n",
        "(x_train1,y_train1), (x_test, y_test) = load_data()\n",
        "\n",
        "\n",
        "#reshaping the training and testing data\n",
        "#NOTE: update the variable 'data' array value places according to the amount of mnist data needed\n",
        "# Example: To have 30k mnist dataset update as data= 30000\n",
        "data = 59000\n",
        "x_train_mnist = x_train1[:(data)].reshape((data, x_train1.shape[1], x_train1.shape[2], 1))\n",
        "y_train_mnist = y_train1[:(data)].reshape((data,1))\n",
        "\n",
        "\n",
        "print('Train', x_train_mnist.shape, y_train_mnist.shape)\n",
        "\n",
        "\n",
        "x_test = x_test.reshape(x_test.shape[0],28,28,1)\n",
        "y_test = y_test.reshape(y_test.shape[0],1)\n",
        "print('Test', x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "YIivDopi3V4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "#from tf.image import rgb_to_grayscale\n",
        "from keras.utils import load_img\n",
        "#from keras.utils import load_img\n",
        "from PIL import Image\n",
        "\n",
        "#path to file containing cgan generated images\n",
        "path_to_files = \"./content\"\n",
        "vectorized_images_x = []\n",
        "vectorized_images_Y = []\n",
        "\n",
        "for _, file_num in enumerate(os.listdir(path_to_files)):\n",
        "  filename = \"./content/%s\" % file_num\n",
        "  print(filename)\n",
        "  for _, file in enumerate(os.listdir(filename)):\n",
        "    path = \"%s/%s\" % (filename,file)\n",
        "    img = load_img(path,target_size=(28,28))\n",
        "    plt.imshow(img,interpolation='nearest',cmap='gray')\n",
        "    #plt.show()\n",
        "    img1 = tf.image.rgb_to_grayscale(\n",
        "    img, name=None)\n",
        "    img_array = np.expand_dims(np.array(img1), axis=2)\n",
        "    img_array.shape\n",
        "    img_array=img_array.reshape(28,28,1)\n",
        "    img_array.shape\n",
        "    vectorized_images_x.append(img_array)\n",
        "    vectorized_images_Y.append(int(file_num))\n",
        "\n",
        "np.savez(\"./mnistlikedataset.npz\",DataX=vectorized_images_x,DataY=vectorized_images_Y)\n",
        "#load and use file\n",
        "import numpy as np\n",
        "\n",
        "path = \"./mnistlikedataset.npz\"\n",
        "with np.load(path) as data:\n",
        "    X_train = data['DataX']\n",
        "    Y_train = data['DataY']\n",
        "\n",
        "#Combine Mnist data and cgan generated data\n",
        "Y_train = Y_train.reshape((Y_train.shape[0], 1))\n",
        "x_train = np.concatenate([x_train_mnist,X_train])\n",
        "y_train = np.concatenate([y_train_mnist,Y_train])\n",
        "print('Train', x_train.shape, y_train.shape)"
      ],
      "metadata": {
        "id": "YaVI6aun2k-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normalizing the values of pixels of images\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n"
      ],
      "metadata": {
        "id": "RuoUHMRQOct_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(5,3))\n",
        "for i in range(15):\n",
        "  ax = fig.add_subplot(2,10, i+1, xticks=[], yticks=[])\n",
        "  ax.imshow(np.squeeze(x_train[i]), cmap='gray')\n",
        "  ax.set_title(y_train[i])"
      ],
      "metadata": {
        "id": "GEJg6OOsOhfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#determine the shape of the image\n",
        "img_shape =x_train.shape[1:]\n",
        "print (img_shape)\n",
        "y_shape =y_train.shape[1:]\n",
        "print (y_shape)\n"
      ],
      "metadata": {
        "id": "BdpjRs45OlRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), activation='relu', input_shape=img_shape))\n",
        "model.add(MaxPool2D((2,2)))\n",
        "model.add(Conv2D(48, (3,3), activation='relu'))\n",
        "model.add(MaxPool2D((2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "0M81yGwvOp8v"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "9iccMIarOt2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model, 'model.jpg' , show_shapes=True)"
      ],
      "metadata": {
        "id": "bmrmU5mROw25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss= 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "x= model.fit(x_train, y_train, epochs=10, batch_size=128, verbose=2, validation_split=0.1)\n"
      ],
      "metadata": {
        "id": "7CPeT8M9O01y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "model.save(\"classifier_cnn.h5\")\n",
        "print(f'Accuracy: {accuracy*100}')"
      ],
      "metadata": {
        "id": "Rszs92fOPVnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = x_test[6]\n",
        "#Lets display the image which we want to predicit\n",
        "plt.imshow(np.squeeze(image), cmap='gray')\n",
        "plt.show\n"
      ],
      "metadata": {
        "id": "DnqAYGkCPaFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image=image.reshape(1, image.shape[0], image.shape[1], image.shape[2])\n",
        "p = model.predict([image])\n",
        "print('predicted: {} '.format(argmax(p)))"
      ],
      "metadata": {
        "id": "w_b3fonDQJzo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}